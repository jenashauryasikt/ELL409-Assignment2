{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNs_for_A2_and_A3_clean.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akKwv18M_uz6"
      },
      "source": [
        "# 2. Neural Networks\n",
        "\n",
        "## 2.4 Convolutional Neural Networks Implemenatation\n",
        "\n",
        "In this notebook, we will implement LeNet-5, AlexNet and VGG-16 archtectures and test them on the Tiny Imagenet Dataset using the Adam Optimizer. We further investigate the relative merits of the Adam, SGD and SGD with momentum optimizers on the MNIST dataset on LeNet-5\n",
        "\n",
        "### Import Statements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj72E_sxIKWu"
      },
      "source": [
        "!unzip /content/drive/MyDrive/tiny-imagenet-200.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb_-ZbR5xshA"
      },
      "source": [
        "#print (torch.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lZO-5V4PdLR"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from datetime import datetime \n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# check device\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "print (DEVICE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xcjx1kR1AObk"
      },
      "source": [
        "### Global Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbJaA3JUQ55S"
      },
      "source": [
        "# Global Variables\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 0.001\n",
        "N_EPOCHS = 60\n",
        "RANDOM_SEED = 32\n",
        "\n",
        "N_CLASSES = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT2xe55h_0jK"
      },
      "source": [
        "### Run Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6Hgii5FYvke"
      },
      "source": [
        "def get_accuracy(model, data_loader, device):\n",
        "    '''\n",
        "    Function for computing the accuracy of the predictions over the entire data_loader\n",
        "    '''\n",
        "    \n",
        "    correct_pred = 0 \n",
        "    n = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for X, y_true in data_loader:\n",
        "\n",
        "            X = X.to(device)\n",
        "            y_true = y_true.to(device)\n",
        "\n",
        "            _, y_prob = model(X)\n",
        "            _, predicted_labels = torch.max(y_prob, 1)\n",
        "\n",
        "            n += y_true.size(0)\n",
        "            correct_pred += (predicted_labels == y_true).sum()\n",
        "\n",
        "    return correct_pred.float() / n\n",
        "\n",
        "def plot_losses(train_losses, valid_losses):\n",
        "    '''\n",
        "    Function for plotting training and validation losses\n",
        "    '''\n",
        "    \n",
        "    # temporarily change the style of the plots to seaborn \n",
        "    plt.style.use('seaborn')\n",
        "\n",
        "    train_losses = np.array(train_losses) \n",
        "    valid_losses = np.array(valid_losses)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize = (8, 4.5))\n",
        "\n",
        "    ax.plot(train_losses, color='green', label='Training loss') \n",
        "    ax.plot(valid_losses, color='orange', label='Testing loss')\n",
        "    ax.set(title=\"Loss across epochs\", \n",
        "            xlabel='Epoch',\n",
        "            ylabel='Loss') \n",
        "    ax.legend()\n",
        "    fig.show()\n",
        "    \n",
        "    # change the plot style to default\n",
        "    plt.style.use('ggplot')\n",
        "\n",
        "def train_optm (train_loader, model, criterion, optimizer, device):\n",
        "    '''\n",
        "    Function for the training step of the training loop\n",
        "    '''\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    \n",
        "    for X, y_true in train_loader:\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        X = X.to(device)\n",
        "        y_true = y_true.to(device)\n",
        "    \n",
        "        # Forward pass\n",
        "        y_hat, _ = model(X) \n",
        "        loss = criterion(y_hat, y_true) \n",
        "        running_loss += loss.item() * X.size(0)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    return model, optimizer, epoch_loss\n",
        "\n",
        "def validate(valid_loader, model, criterion, device):\n",
        "    '''\n",
        "    Function for the validation step of the training loop\n",
        "    '''\n",
        "   \n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    \n",
        "    for X, y_true in valid_loader:\n",
        "    \n",
        "        X = X.to(device)\n",
        "        y_true = y_true.to(device)\n",
        "\n",
        "        # Forward pass and record loss\n",
        "        y_hat, _ = model(X) \n",
        "        loss = criterion(y_hat, y_true) \n",
        "        running_loss += loss.item() * X.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(valid_loader.dataset)\n",
        "        \n",
        "    return model, epoch_loss\n",
        "\n",
        "def training_loop_optm (model, criterion, optimizer, train_loader, valid_loader, epochs, device, print_every=1):\n",
        "    '''\n",
        "    Function defining the entire training loop\n",
        "    '''\n",
        "    \n",
        "    # set objects for storing metrics\n",
        "    best_loss = 1e10\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        " \n",
        "    # Train model\n",
        "    for epoch in range(0, epochs):\n",
        "\n",
        "        # training\n",
        "        model, optimizer, train_loss = train_optm (train_loader, model, criterion, optimizer, device)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # validation\n",
        "        with torch.no_grad():\n",
        "            model, valid_loss = validate(valid_loader, model, criterion, device)\n",
        "            valid_losses.append(valid_loss)\n",
        "\n",
        "        if epoch % print_every == (print_every - 1):\n",
        "            \n",
        "            train_acc = get_accuracy(model, train_loader, device=device)\n",
        "            valid_acc = get_accuracy(model, valid_loader, device=device)\n",
        "                \n",
        "            print(f'{datetime.now().time().replace(microsecond=0)}     '\n",
        "                  f'Epoch: {epoch}\\t'\n",
        "                  f'Train loss: {train_loss:.3f}\\t'\n",
        "                  f'Test loss: {valid_loss:.3f}\\t'\n",
        "                  f'Train accuracy: {100 * train_acc:.3f}\\t'\n",
        "                  f'Test accuracy: {100 * valid_acc:.3f}')\n",
        "            \n",
        "    plot_losses(train_losses, valid_losses)\n",
        "    \n",
        "    return model, optimizer, (train_losses, valid_losses)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wik1buJxYJaf"
      },
      "source": [
        "## LeNet-5\n",
        "\n",
        "\n",
        "### Transform data for LeNet-5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pox8iDGVc5ov"
      },
      "source": [
        "# Path to train, test and val data\n",
        "here = os.path.dirname(os.path.realpath('__file__'))\n",
        "subdir = \"tiny-imagenet-200\"\n",
        "test_dir = os.path.join(here, subdir, \"test\")\n",
        "train_dir = os.path.join(here, subdir, \"train\")\n",
        "val_dir = os.path.join(here, subdir, \"val\")\n",
        "\n",
        "# Transform images into 32 pixels x 32 pixels as reqd by LeNet-5\n",
        "mean = (0.48093379, 0.44808328, 0.39650237)\n",
        "stddev = (0.22996924, 0.22610814, 0.22566715)\n",
        "my_trans = transforms.Compose([transforms.Resize((32, 32)),\n",
        "                                 transforms.ToTensor(), transforms.Normalize(mean, stddev)])\n",
        "\n",
        "# Make dataset objects\n",
        "#test_data = datasets.ImageFolder (test_dir, transform = my_trans)\n",
        "tot_data = datasets.ImageFolder (train_dir, transform = my_trans)\n",
        "#print (len(tot_data[0][0][0][0]))\n",
        "train_data, val_data = random_split (tot_data, [90000, 10000])\n",
        "#print (len(val_data[0][0]))\n",
        "#val_data = datasets.ImageFolder (val_dir, transform = my_trans)\n",
        "#test_load = DataLoader (dataset=test_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "train_load = DataLoader (dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_load = DataLoader (dataset=val_data, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUMf4SxfAbeC"
      },
      "source": [
        "### LeNet-5 Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFqXksKUTYMD"
      },
      "source": [
        "class LeNet5(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes):\n",
        "        super(LeNet5, self).__init__()\n",
        "        \n",
        "        self.feature_extractor = nn.Sequential(            \n",
        "            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1),\n",
        "            nn.Tanh(),\n",
        "            nn.AvgPool2d(kernel_size=2),\n",
        "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
        "            nn.Tanh(),\n",
        "            nn.AvgPool2d(kernel_size=2),\n",
        "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(in_features=120, out_features=84),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(in_features=84, out_features=n_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        logits = self.classifier(x)\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        return logits, probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cG-c8PXtAVR_"
      },
      "source": [
        "### Intialize LeNet-5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfFLE_sVZueF"
      },
      "source": [
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "model = LeNet5(N_CLASSES).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NhnEl9FAjJ2"
      },
      "source": [
        "### LeNet-5 with optimizer\n",
        "\n",
        "Run 120 epochs on AlexNet with Adam Optimizer on Tiny ImageNet with a batch size of 32 and constant learning rate of 0.001."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRf8EAGVwSWe"
      },
      "source": [
        "model, optimizer, _ = training_loop_optm (model, criterion, optimizer, train_load, val_load, N_EPOCHS, DEVICE, print_every = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpkUHxVIcbW8"
      },
      "source": [
        "## AlexNet\n",
        "\n",
        "### Transform data (AlexNet and VGG-16)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8ni2k7V9aaB"
      },
      "source": [
        "# Preprocess images\n",
        "\n",
        "# Path to train, test and val data\n",
        "here = os.path.dirname(os.path.realpath('__file__'))\n",
        "subdir = \"tiny-imagenet-200\"\n",
        "test_dir = os.path.join(here, subdir, \"test\")\n",
        "train_dir = os.path.join(here, subdir, \"train\")\n",
        "val_dir = os.path.join(here, subdir, \"val\")\n",
        "\n",
        "mean = (0.48093379, 0.44808328, 0.39650237)\n",
        "stddev = (0.22996924, 0.22610814, 0.22566715)\n",
        "\n",
        "my_trans = transforms.Compose([\n",
        "  #transforms.Resize(256),\n",
        "  #transforms.CenterCrop(224),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize(mean, stddev),\n",
        "])\n",
        "\n",
        "# Make dataset objects\n",
        "#test_data = datasets.ImageFolder (test_dir, transform = my_trans)\n",
        "#val_data = datasets.ImageFolder (val_dir, transform = my_trans)\n",
        "tot_data = datasets.ImageFolder (train_dir, transform = my_trans)\n",
        "train_data, val_data = random_split (tot_data, [90000, 10000])\n",
        "#test_load = DataLoader (dataset=test_data, batch_size=BATCH_SIZE, \n",
        "#                         shuffle=True)\n",
        "#print (len(tot_data[0][0][0]))\n",
        "train_load = DataLoader (dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_load = DataLoader (dataset=val_data, batch_size=BATCH_SIZE, \n",
        "                          shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udXa0IDEAyGe"
      },
      "source": [
        "### AlexNet Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h33Lydajcj4L"
      },
      "source": [
        "class AlexNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes: int = 1000) -> None:\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        #self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.features(x)\n",
        "        #x = self.avgpool(x)\n",
        "        out = torch.flatten(x, 1)\n",
        "        logit = self.classifier(out)\n",
        "        probs = F.softmax(logit, dim=1)\n",
        "        return logit, probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgyuNVkMA0gt"
      },
      "source": [
        "### Initialize AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaUiOKn1a0Dj"
      },
      "source": [
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "model = AlexNet (N_CLASSES).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0ksCLIlA5Dx"
      },
      "source": [
        "### AlexNet with Adam optimizer\n",
        "\n",
        "Run 120 epochs on AlexNet with Adam Optimizer on Tiny ImageNet with a batch size of 64 and learning rate of 0.001"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5DYWFmc-Brj"
      },
      "source": [
        "model, optimizer, _ = training_loop_optm (model, criterion, optimizer, train_load, val_load, N_EPOCHS, DEVICE, print_every = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Uze4KaA_cDK"
      },
      "source": [
        "#VGG-16\n",
        "\n",
        "## VGG-16 class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqkEw3d7_eB8"
      },
      "source": [
        "def conv_layer(chann_in, chann_out, k_size, p_size):\n",
        "    layer = nn.Sequential(\n",
        "        nn.Conv2d(chann_in, chann_out, kernel_size=k_size, padding=p_size),\n",
        "        nn.BatchNorm2d(chann_out),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    return layer\n",
        "\n",
        "def vgg_conv_block(in_list, out_list, k_list, p_list, pooling_k, pooling_s):\n",
        "\n",
        "    layers = [ conv_layer(in_list[i], out_list[i], k_list[i], p_list[i]) for i in range(len(in_list)) ]\n",
        "    layers += [ nn.MaxPool2d(kernel_size = pooling_k, stride = pooling_s)]\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "def vgg_fc_layer(size_in, size_out):\n",
        "    layer = nn.Sequential(\n",
        "        nn.Linear(size_in, size_out),\n",
        "        nn.BatchNorm1d(size_out),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    return layer\n",
        "\n",
        "class VGG16(nn.Module):\n",
        "    def __init__(self, n_classes=1000):\n",
        "        super(VGG16, self).__init__()\n",
        "\n",
        "        # Conv blocks (BatchNorm + ReLU activation added in each block)\n",
        "        self.layer1 = vgg_conv_block([3,64], [64,64], [3,3], [1,1], 2, 2)\n",
        "        self.layer2 = vgg_conv_block([64,128], [128,128], [3,3], [1,1], 2, 2)\n",
        "        self.layer3 = vgg_conv_block([128,256,256], [256,256,256], [3,3,3], [1,1,1], 2, 2)\n",
        "        self.layer4 = vgg_conv_block([256,512,512], [512,512,512], [3,3,3], [1,1,1], 2, 2)\n",
        "        self.layer5 = vgg_conv_block([512,512,512], [512,512,512], [3,3,3], [1,1,1], 2, 2)\n",
        "\n",
        "        #self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "\n",
        "        # FC layers\n",
        "        self.layer6 = vgg_fc_layer(512*7*7, 4096)\n",
        "        self.layer7 = vgg_fc_layer(4096, 4096)\n",
        "\n",
        "        # Final layer\n",
        "        self.layer8 = nn.Linear(4096, n_classes)\n",
        "\n",
        "        self.layer82 = nn.Linear(512, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.layer5(out)\n",
        "        #out = self.avgpool(out)\n",
        "        #out = torch.flatten(out, 1)\n",
        "        vgg16_features = self.layer5(out)\n",
        "        out = vgg16_features.view(out.size(0), -1)\n",
        "        #out = self.layer6(out)\n",
        "        #out = self.layer7(out)\n",
        "        #out = self.layer8(out)\n",
        "        out = self.layer82(out)\n",
        "        probs = F.softmax(out, dim=1)\n",
        "        return out, probs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOab6zzwBQdR"
      },
      "source": [
        "### VGG-16 initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6JGYsxG_kbu"
      },
      "source": [
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "model = VGG16(N_CLASSES).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gEP18DOBV1f"
      },
      "source": [
        "### VGG-16 with optimizer\n",
        "\n",
        "Run 60 epochs on VGG-16 with Adam Optimizer with a batch size of 64 and a learning rate of 0.001 on Tiny ImageNet Dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0Liooeg_p9W"
      },
      "source": [
        "model, optimizer, _ = training_loop_optm (model, criterion, optimizer, train_load, val_load, N_EPOCHS, DEVICE, print_every = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6WS1GDzfAJ4"
      },
      "source": [
        "## 2.5 Comparing Optimizers on LeNet-5\n",
        "\n",
        "Here we compare SGD, SGD with momentum and Adam on MNIST Dataset using LeNet-5 for 60 epochs with a learning rate of 0.001 and a batch size of 64.\n",
        "\n",
        "### Importing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYfPZhoZfWdc"
      },
      "source": [
        "# Path to train, test and val data\n",
        "here = os.path.dirname(os.path.realpath('__file__'))\n",
        "subdir = \"mnist\"\n",
        "test_dir = os.path.join(here, subdir, \"test\")\n",
        "train_dir = os.path.join(here, subdir, \"train\")\n",
        "val_dir = os.path.join(here, subdir, \"val\")\n",
        "\n",
        "# Transform images into 32 pixels x 32 pixels as reqd by LeNet-5\n",
        "mean = (0.44808328)\n",
        "stddev = (0.22610814)\n",
        "my_trans_mnist = transforms.Compose([\n",
        "                               transforms.Resize((32, 32)),\n",
        "                                 transforms.ToTensor(), \n",
        "                               transforms.Normalize(mean, stddev)])\n",
        "\n",
        "# Make dataset objects\n",
        "train_data_mnist = datasets.MNIST (train_dir, train = True, transform = my_trans_mnist, download = True)\n",
        "test_data_mnist = datasets.MNIST (test_dir, train = False, transform = my_trans_mnist, download = True)\n",
        "train_load_mnist = DataLoader (dataset=train_data_mnist, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_load_mnist = DataLoader (dataset=test_data_mnist, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "#print (len(train_data[0][0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8wQ3vjflVqP"
      },
      "source": [
        "### LeNet-5\n",
        "\n",
        "We slightly modify LeNet-5 from what was used earlier because now we are working with only one input channel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HArR5L1HyDBM"
      },
      "source": [
        "class LeNet5(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes):\n",
        "        super(LeNet5, self).__init__()\n",
        "        \n",
        "        self.feature_extractor = nn.Sequential(            \n",
        "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),\n",
        "            nn.Tanh(),\n",
        "            nn.AvgPool2d(kernel_size=2),\n",
        "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
        "            nn.Tanh(),\n",
        "            nn.AvgPool2d(kernel_size=2),\n",
        "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(in_features=120, out_features=84),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(in_features=84, out_features=n_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        logits = self.classifier(x)\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        return logits, probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFSwiUjbfNn5"
      },
      "source": [
        "### LeNet-5 with SGD optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxfe42ftlhhu"
      },
      "source": [
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "model = LeNet5(N_CLASSES).to(DEVICE)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model, optimizer, _ = training_loop_optm (model, criterion, optimizer, train_load_mnist, test_load_mnist, N_EPOCHS, DEVICE, print_every = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uB7HQAja2niW"
      },
      "source": [
        "### LeNet-5 with SGD with Momentum optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntK-7lLXfU4M"
      },
      "source": [
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "model = LeNet5(N_CLASSES).to(DEVICE)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum = 0.5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model, optimizer, _ = training_loop_optm (model, criterion, optimizer, train_load_mnist, test_load_mnist, N_EPOCHS, DEVICE, print_every = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dzx9V1XWfXFd"
      },
      "source": [
        "### LeNet-5 with Adam optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hj3HWS_jlneb"
      },
      "source": [
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "model = LeNet5(N_CLASSES).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model, optimizer, _ = training_loop_optm (model, criterion, optimizer, train_load_mnist, test_load_mnist, N_EPOCHS, DEVICE, print_every = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erOG1d5ZW7Oz"
      },
      "source": [
        "# 3. Learning++\n",
        "\n",
        "## 3.3 Cross Training \n",
        "\n",
        "Here we will perform cross training by first training on SVHN dataset and testing on MNIST and vice versa\n",
        "\n",
        "### Importing SVHN Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dk4RSHDBWiks"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf_GkCYNluNI"
      },
      "source": [
        "# Path to train, test and val data\n",
        "here = os.path.dirname(os.path.realpath('__file__'))\n",
        "subdir = \"svhn\"\n",
        "test_dir = os.path.join(here, subdir, \"test\")\n",
        "train_dir = os.path.join(here, subdir, \"train\")\n",
        "val_dir = os.path.join(here, subdir, \"val\")\n",
        "\n",
        "# Transform images into 32 pixels x 32 pixels as reqd by LeNet-5\n",
        "mean = (0.44808328)\n",
        "stddev = (0.22610814)\n",
        "my_trans_svhn = transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
        "                                    transforms.Resize((32, 32)),\n",
        "                                    transforms.ToTensor(), \n",
        "                                    transforms.Normalize(mean, stddev)])\n",
        "\n",
        "# Make dataset objects\n",
        "train_data_svhn = datasets.SVHN (train_dir, split = 'train', transform = my_trans_svhn, download = True)\n",
        "test_data_svhn = datasets.SVHN (test_dir, split = 'test', transform = my_trans_svhn, download = True)\n",
        "train_load_svhn = DataLoader (dataset=train_data_svhn, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_load_svhn = DataLoader (dataset=test_data_svhn, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "print (len(train_data_svhn[0][0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJd6_Afxa9xv"
      },
      "source": [
        "### Training on SVHN and testing on MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5rRx-41ahpL"
      },
      "source": [
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "model = LeNet5(N_CLASSES).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model, optimizer, _ = training_loop_optm (model, criterion, optimizer, train_load_svhn, test_load_mnist, N_EPOCHS, DEVICE, print_every = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlrEvNKIbbqK"
      },
      "source": [
        "### Training on MNIST and testing on SVHN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kABmd6xbUt5"
      },
      "source": [
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "model = LeNet5(N_CLASSES).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model, optimizer, _ = training_loop_optm (model, criterion, optimizer, train_load_mnist, test_load_svhn, N_EPOCHS, DEVICE, print_every = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2NU3NXbbyTn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}